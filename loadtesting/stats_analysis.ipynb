{
 "cells": [
  {
   "cell_type": "code",
   "id": "f546290dcd056f13",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pytz"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d6de811535875d3",
   "metadata": {},
   "source": [
    "basedir = \"data/2024-07-08/\"\n",
    "locust_data_file = basedir+\"data_stats_history.csv\"\n",
    "kepler_data_file = basedir+\"kepler.csv\"\n",
    "pdu_data_file = basedir+\"pdu.csv\"\n",
    "\n",
    "stages = [\n",
    "    {\"users\": 100, \"spawn_rate\": 2},\n",
    "    {\"users\": 200, \"spawn_rate\": 20},\n",
    "    {\"users\": 300, \"spawn_rate\": 20},\n",
    "    {\"users\": 500, \"spawn_rate\": 20},\n",
    "    {\"users\": 800, \"spawn_rate\": 20},\n",
    "    {\"users\": 1300, \"spawn_rate\": 50},\n",
    "    {\"users\": 2100, \"spawn_rate\": 50}\n",
    "]\n",
    "\n",
    "valid_users = set()\n",
    "for stage in stages:\n",
    "    valid_users.add(stage['users'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f1126266d6019b3",
   "metadata": {},
   "source": [
    "# CSV Daten in DataFrame einlesen\n",
    "locust_df = pd.read_csv(\"%s\" % locust_data_file)\n",
    "\n",
    "# Konvertiere die Zeitstempel in ein datetime-Format, um die Daten einfacher zu analysieren\n",
    "locust_df['Timestamp'] = pd.to_datetime(locust_df['Timestamp'], unit='s')\n",
    "# Zeitzone in Deutschland festlegen\n",
    "germany_tz = pytz.timezone('Europe/Berlin')\n",
    "locust_df['Timestamp'] = locust_df['Timestamp'].dt.tz_localize('UTC').dt.tz_convert(germany_tz)\n",
    "\n",
    "# Setze den Zeitstempel als Index\n",
    "locust_df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Entferne die Spalte 'Type'\n",
    "locust_df.drop(columns=['Type'], inplace=True)\n",
    "\n",
    "# Filtere die Zeilen, bei denen 'Request Count' gleich 0 ist\n",
    "locust_df = locust_df[locust_df['Total Request Count'] != 0]\n",
    "\n",
    "# Entferne alle Zeilen, bei denen 'users' nicht im Set 'valid_users' ist\n",
    "locust_df = locust_df[locust_df['User Count'].isin(valid_users)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e6b1bd8776b87a",
   "metadata": {},
   "source": [
    "locust_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get the min and max index (time) for the current stage\n",
    "start_time, end_time = locust_df.index.min(), locust_df.index.max()\n",
    "# Convert the timezoned datetime to naive datetime (UTC or localize as needed)\n",
    "start_time = start_time.tz_convert(\"Europe/Berlin\").tz_localize(None)\n",
    "end_time = end_time.tz_convert(\"Europe/Berlin\").tz_localize(None)\n",
    "print(\"Start:\",start_time, \"; End:\",end_time)"
   ],
   "id": "7096181dcc2cb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37bd4ac4d783271e",
   "metadata": {},
   "source": [
    "# Box plot für Total Average Response Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "locust_df.boxplot(column='Total Average Response Time', by='User Count', grid=False)\n",
    "plt.title('Total Average Response Time by Stage')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('User Count')\n",
    "plt.ylabel('Total Average Response Time (ms)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Box plot für Total Median Response Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "locust_df.boxplot(column='Total Median Response Time', by='User Count', grid=False)\n",
    "plt.title('Total Median Response Time by Stage')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('User Count')\n",
    "plt.ylabel('Total Median Response Time (ms)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18bc7f03ddfcf003",
   "metadata": {},
   "source": [
    "# Fehlerrate analysieren\n",
    "locust_df['Failure Rate'] = locust_df['Total Failure Count'] / (\n",
    "            locust_df['Total Request Count'] + locust_df['Total Failure Count'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "locust_df.groupby('User Count')['Failure Rate'].mean().plot(kind='bar', rot=45)\n",
    "plt.title('Average Failure Rate by Stage')\n",
    "plt.xlabel('User Count')\n",
    "plt.ylabel('Failure Rate')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11e7a30b897c45e7",
   "metadata": {},
   "source": [
    "# Gesamte Läufe vergleichen\n",
    "summary_stats = locust_df.groupby('User Count').agg({\n",
    "    'Total Average Response Time': ['mean', 'median', 'std'],\n",
    "    'Total Median Response Time': ['mean', 'median', 'std'],\n",
    "    'Failure Rate': ['mean', 'median', 'std']\n",
    "})\n",
    "\n",
    "print(summary_stats)\n",
    "\n",
    "# Visualisierung der zusammengefassten Statistiken\n",
    "summary_stats.plot(kind='bar', subplots=True, layout=(3, 3), figsize=(18, 16))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f86ccf0a07252c9c",
   "metadata": {},
   "source": [
    "# Calculate confidence intervals for the 'Total Median Response Time'\n",
    "grouped_stats = locust_df.groupby('User Count')['Total Median Response Time'].agg(['mean', 'count', 'std'])\n",
    "\n",
    "# Calculate t-value for a 95% confidence interval\n",
    "t_value = stats.t.ppf(0.975, grouped_stats['count'] - 1)  # 0.975 corresponds to (1 - alpha/2)\n",
    "\n",
    "# Calculate the margin of error\n",
    "grouped_stats['margin_of_error'] = t_value * grouped_stats['std'] / (grouped_stats['count'] ** 0.5)\n",
    "\n",
    "# Calculate the lower and upper bounds of the confidence interval\n",
    "grouped_stats['ci_low'] = grouped_stats['mean'] - grouped_stats['margin_of_error']\n",
    "grouped_stats['ci_high'] = grouped_stats['mean'] + grouped_stats['margin_of_error']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(grouped_stats.index, grouped_stats['mean'],\n",
    "             yerr=grouped_stats['margin_of_error'],\n",
    "             fmt='-o', ecolor='r', capsize=5, capthick=2, label='95% CI')\n",
    "\n",
    "plt.title('95% Confidence Intervals for Mean Total Median Response Time')\n",
    "plt.xlabel('User Count')\n",
    "plt.ylabel('Total Median Response Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1db15cb84f997657",
   "metadata": {},
   "source": [
    "# Calculate confidence intervals for the 'Failure Rate'\n",
    "grouped_stats = locust_df.groupby('User Count')['Failure Rate'].agg(['mean', 'count', 'std'])\n",
    "\n",
    "# Calculate t-value for a 95% confidence interval\n",
    "t_value = stats.t.ppf(0.975, grouped_stats['count'] - 1)  # 0.975 corresponds to (1 - alpha/2)\n",
    "\n",
    "# Calculate the margin of error\n",
    "grouped_stats['margin_of_error'] = t_value * grouped_stats['std'] / (grouped_stats['count'] ** 0.5)\n",
    "\n",
    "# Calculate the lower and upper bounds of the confidence interval\n",
    "grouped_stats['ci_low'] = grouped_stats['mean'] - grouped_stats['margin_of_error']\n",
    "grouped_stats['ci_high'] = grouped_stats['mean'] + grouped_stats['margin_of_error']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(grouped_stats.index, grouped_stats['mean'],\n",
    "             yerr=grouped_stats['margin_of_error'],\n",
    "             fmt='-o', ecolor='r', capsize=5, capthick=2, label='95% CI')\n",
    "\n",
    "plt.title('95% Confidence Intervals for Mean Failure Rate')\n",
    "plt.xlabel('User Count')\n",
    "plt.ylabel('Failure Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Determine the appropriate unit for the total energy consumed\n",
    "def convert_energy(total_energy_joules):\n",
    "    if total_energy_joules >= 1e6:  # 1 Megajoule = 1,000,000 Joules\n",
    "        energy_unit = \"MJ\"\n",
    "        total_energy = total_energy_joules / 1e6\n",
    "    elif total_energy_joules >= 1e3:  # 1 Kilojoule = 1,000 Joules\n",
    "        energy_unit = \"kJ\"\n",
    "        total_energy = total_energy_joules / 1e3\n",
    "    else:\n",
    "        energy_unit = \"J\"\n",
    "        total_energy = total_energy_joules\n",
    "    return total_energy, energy_unit\n",
    "\n",
    "def transform_joules(energy, from_unit, to_unit):\n",
    "    # Conversion factors to Joules\n",
    "    conversion_to_joules = {\n",
    "        \"MJ\": 1e6,\n",
    "        \"kJ\": 1e3,\n",
    "        \"J\": 1\n",
    "    }\n",
    "    \n",
    "    if from_unit not in conversion_to_joules:\n",
    "        raise ValueError(f\"Unknown from_unit: {from_unit}\")\n",
    "    \n",
    "    if to_unit not in conversion_to_joules:\n",
    "        raise ValueError(f\"Unknown to_unit: {to_unit}\")\n",
    "    \n",
    "    # Convert from original unit to Joules\n",
    "    energy_in_joules = energy * conversion_to_joules[from_unit]\n",
    "    \n",
    "    # Convert from Joules to the target unit\n",
    "    energy_in_target_unit = energy_in_joules / conversion_to_joules[to_unit]\n",
    "    \n",
    "    return energy_in_target_unit"
   ],
   "id": "bda16a8d8a016bda",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cfffd6fe8c9c2ee",
   "metadata": {},
   "source": [
    "kepler_df = pd.read_csv(kepler_data_file,  parse_dates=['Time'])\n",
    "kepler_df['Time'] = pd.to_datetime(kepler_df['Time'])  # Ensure consistent timezone\n",
    "# Ensure the DataFrame is sorted by Time\n",
    "kepler_df = kepler_df.sort_values(by='Time')\n",
    "kepler_df.index = pd.to_datetime(kepler_df.index)\n",
    "for column in kepler_df.columns:\n",
    "    if column != 'Time':\n",
    "        kepler_df[column] = kepler_df[column].ffill().fillna(0)\n",
    "\n",
    "def calculate_kepler_energy_consumption(kepler_df, start_time, end_time):\n",
    "    # Ensure the DataFrame is sorted by Time\n",
    "    kepler_df = kepler_df.sort_values(by='Time')\n",
    "    \n",
    "    # Check if start_time is within the DataFrame's time range\n",
    "    if start_time < kepler_df['Time'].min():\n",
    "        print(f\"Start time {start_time} is before the first timestamp. Using the first available value.\")\n",
    "        start_values = kepler_df.iloc[0].drop(labels='Time')\n",
    "    else:\n",
    "        start_values = kepler_df.loc[kepler_df['Time'] >= start_time].iloc[0].drop(labels='Time')\n",
    "\n",
    "    # Check if end_time is within the DataFrame's time range\n",
    "    if end_time > kepler_df['Time'].max():\n",
    "        print(f\"End time {end_time} is after the last timestamp. Using the last available value.\")\n",
    "        end_values = kepler_df.iloc[-1].drop(labels='Time')\n",
    "    elif end_time<kepler_df['Time'].min():\n",
    "        return 0, \"J\"\n",
    "    else:\n",
    "        end_values = kepler_df.loc[kepler_df['Time'] <= end_time].iloc[-1].drop(labels='Time')\n",
    "    \n",
    "    # Calculate the difference between end and start values\n",
    "    energy_difference = end_values.values - start_values.values\n",
    "\n",
    "    # Sum up the differences\n",
    "    total_energy_sum = energy_difference.sum()\n",
    "\n",
    "    return convert_energy(total_energy_sum)\n",
    "\n",
    "# Calculate energy consumption for the specified time range\n",
    "total_energy_kepler, unit_kepler = calculate_kepler_energy_consumption(kepler_df, start_time, end_time)\n",
    "\n",
    "print(f\"Total energy consumed from {start_time} to {end_time} tracked by kepler: {total_energy_kepler} {unit_kepler}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pdu_df = pd.read_csv(pdu_data_file,  parse_dates=['Time'])\n",
    "pdu_df['Time'] = pd.to_datetime(pdu_df['Time'])  # Ensure consistent timezone\n",
    "# Ensure the DataFrame is sorted by Time\n",
    "pdu_df = pdu_df.sort_values(by='Time')\n",
    "pdu_df.index = pd.to_datetime(pdu_df.index)\n",
    "\n",
    "# Function to remove ' W' and convert to numeric\n",
    "def strip_w_convert(series):\n",
    "    return pd.to_numeric(series.str.replace(' W', ''), errors='coerce')\n",
    "\n",
    "# Apply the function to all columns except 'Time'\n",
    "for column in pdu_df.columns:\n",
    "    if column != 'Time':\n",
    "        pdu_df[column] = strip_w_convert(pdu_df[column])\n",
    "\n",
    "def calculate_pdu_energy_consumption(pdu_df, start_time, end_time):\n",
    "    # Filter the DataFrame for the specified time range\n",
    "    time_filtered_df = pdu_df[(pdu_df['Time'] >= start_time) & (pdu_df['Time'] <= end_time)].copy()\n",
    "\n",
    "    if time_filtered_df.empty:\n",
    "        print(\"The filtered DataFrame is empty. Ensure the time range is within the data bounds.\")\n",
    "        return convert_energy(0)\n",
    "\n",
    "    # Calculate time difference between consecutive measurements in seconds\n",
    "    time_filtered_df.loc[:, 'Time_diff'] = time_filtered_df['Time'].diff().dt.total_seconds()\n",
    "\n",
    "    # Calculate the energy consumed during each interval (Power * Time_diff)\n",
    "    time_filtered_df['Energy_Joules'] = time_filtered_df['Value'] * time_filtered_df['Time_diff']\n",
    "\n",
    "    # Summing up the energy consumed\n",
    "    total_energy_joules = time_filtered_df['Energy_Joules'].sum()\n",
    "\n",
    "    # Convert the total energy to the appropriate unit\n",
    "    return convert_energy(total_energy_joules)\n",
    "\n",
    "# Calculate energy consumption for the specified time range\n",
    "total_energy_pdu, unit_pdu = calculate_pdu_energy_consumption(pdu_df, start_time, end_time)\n",
    "\n",
    "print(f\"Total energy consumed from {start_time} to {end_time} tracked by pdu metrics: {total_energy_pdu} {unit_pdu}\")\n"
   ],
   "id": "bfe9070eb154a3d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kepler_energy = []\n",
    "pdu_energy = []\n",
    "user_counts = []\n",
    "\n",
    "# Loop through each stage\n",
    "for stage in stages:\n",
    "    stage_users = stage['users']\n",
    "    stage_df = locust_df[locust_df['User Count'] == stage_users]\n",
    "    \n",
    "    # Append zeros for empty DataFrame and continue\n",
    "    if stage_df.empty:\n",
    "        print(\"The filtered DataFrame is empty. Ensure the time range is within the data bounds.\")\n",
    "        kepler_energy.append(0)\n",
    "        pdu_energy.append(0)\n",
    "        user_counts.append(stage_users)\n",
    "        continue\n",
    "\n",
    "    # Get the min and max index (time) for the current stage\n",
    "    start_time, end_time = stage_df.index.min(), stage_df.index.max()\n",
    "    \n",
    "    # Convert the timezoned datetime to naive datetime (UTC or localize as needed)\n",
    "    start_time = start_time.tz_convert(\"Europe/Berlin\").tz_localize(None)\n",
    "    end_time = end_time.tz_convert(\"Europe/Berlin\").tz_localize(None)\n",
    "    print(\"Stage:\",stage_users,\" From:\",start_time,\" To:\", end_time)\n",
    "        \n",
    "    k_energy, k_unit = calculate_kepler_energy_consumption(kepler_df, start_time, end_time)\n",
    "    p_energy, p_unit = calculate_pdu_energy_consumption(pdu_df, start_time, end_time)\n",
    "    \n",
    "    kepler_energy.append(transform_joules(k_energy, k_unit, \"kJ\"))\n",
    "    pdu_energy.append(transform_joules(p_energy, p_unit, \"kJ\"))\n",
    "    user_counts.append(stage_users)\n",
    "\n",
    "print(kepler_energy, pdu_energy, user_counts)"
   ],
   "id": "795e1c5247082d42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot lines with markers to make data points visible\n",
    "ax.plot(user_counts, kepler_energy, label='Kepler Energy Consumption', color='blue', marker='o', markersize=4, zorder=50)\n",
    "ax.plot(user_counts, pdu_energy, label='PDU Energy Consumption', color='green', marker='o', markersize=4, zorder=50)\n",
    "\n",
    "# Fill between for kepler energy\n",
    "ax.fill_between(user_counts, kepler_energy, color='blue', alpha=0.6, step='post', zorder=5)\n",
    "\n",
    "# Fill between for pdu energy\n",
    "ax.fill_between(user_counts, pdu_energy, color='green', alpha=0.6, step='post', zorder=1)\n",
    "\n",
    "# Additional Plot Settings\n",
    "ax.set_xlabel('User Count')\n",
    "ax.set_ylabel('Energy Consumption (KiloJoules)')\n",
    "ax.set_title('Energy Consumption by User Count Stage (Kepler vs PDU)')\n",
    "# Set x-axis ticks and labels only to show user counts\n",
    "ax.set_xticks(user_counts)\n",
    "ax.set_xticklabels(user_counts)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Rotate x-ticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ],
   "id": "56ea1e879333850b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "energy_efficiency_kepler = []\n",
    "energy_efficiency_pdu = []\n",
    "successful_requests_per_stage = []\n",
    "failed_requests_per_stage = []\n",
    "requests_per_stage = []\n",
    "\n",
    "# Loop through each stage\n",
    "for stage in stages:\n",
    "    stage_users = stage['users']\n",
    "    stage_df = locust_df[locust_df['User Count'] == stage_users]\n",
    "    \n",
    "    # Append zeros for empty DataFrame and continue\n",
    "    if stage_df.empty:\n",
    "        print(\"The filtered DataFrame is empty. Ensure the time range is within the data bounds.\")\n",
    "        energy_efficiency_kepler.append(0)\n",
    "        energy_efficiency_pdu.append(0)\n",
    "        successful_requests_per_stage.append(0)\n",
    "        failed_requests_per_stage.append(0)\n",
    "        requests_per_stage.append(0)\n",
    "        continue\n",
    "\n",
    "    successful_requests = stage_df['Total Request Count'].max() - stage_df['Total Failure Count'].max()\n",
    "    failed_requests = stage_df['Total Failure Count'].max()\n",
    "    requests = stage_df['Total Request Count'].max()\n",
    "    \n",
    "    # Calculate energy efficiency (successful requests per kJ consumed)\n",
    "    k_energy_efficiency = successful_requests / kepler_energy[user_counts.index(stage_users)]\n",
    "    pdu_energy_efficiency = successful_requests / pdu_energy[user_counts.index(stage_users)]\n",
    "    \n",
    "    energy_efficiency_kepler.append(k_energy_efficiency)\n",
    "    energy_efficiency_pdu.append(pdu_energy_efficiency)\n",
    "    successful_requests_per_stage.append(successful_requests)\n",
    "    failed_requests_per_stage.append(failed_requests)\n",
    "    requests_per_stage.append(requests)\n",
    "\n",
    "# Calculate total energy efficiency\n",
    "total_successful_requests = sum(successful_requests_per_stage)\n",
    "total_energy_kepler_kj = sum(kepler_energy)\n",
    "total_energy_pdu_kj = sum(pdu_energy)\n",
    "\n",
    "total_efficiency_kepler = total_successful_requests / total_energy_kepler_kj\n",
    "total_efficiency_pdu = total_successful_requests / total_energy_pdu_kj\n",
    "\n",
    "print(\"Total Energy Efficiency (Kepler):\", total_efficiency_kepler, \"successful requests/kJ\")\n",
    "print(\"Total Energy Efficiency (PDU):\", total_efficiency_pdu, \"successful requests/kJ\")"
   ],
   "id": "db4b95d2d0344693",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot energy efficiency for each stage and successful/failed requests\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "color = 'tab:blue'\n",
    "ax1.set_ylabel('Request Counts', color=color) \n",
    "\n",
    "# Plot successful and failed requests\n",
    "ax1.plot(user_counts, requests_per_stage, label='Total Requests', color='red', marker='s', linestyle='--')\n",
    "ax1.plot(user_counts, successful_requests_per_stage, label='Successfull Requests', color='green', marker='s', linestyle='--')\n",
    "ax1.plot(user_counts, failed_requests_per_stage, label='Failed Requests', color='orange', marker='x', linestyle='--')\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "# Ensure the y-axis starts at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Set x-axis ticks and labels only to show user counts\n",
    "ax1.set_xticks(user_counts)\n",
    "ax1.set_xticklabels(user_counts)\n",
    "\n",
    "plt.title('Aggregated Total, Successfully and Failed Requests by User Count Stage (Resetted on each Stage)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ],
   "id": "a70943e1709939dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot energy efficiency for each stage and successful/failed requests\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('User Count')\n",
    "ax1.set_ylabel('Energy Efficiency', color=color)\n",
    "\n",
    "# Plot energy efficiency\n",
    "ax1.plot(user_counts, energy_efficiency_kepler, label='Kepler Energy Efficiency', color='blue', marker='o', markersize=4)\n",
    "ax1.plot(user_counts, energy_efficiency_pdu, label='PDU Energy Efficiency', color='green', marker='o', markersize=4)\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid()\n",
    "\n",
    "# Ensure the y-axis starts at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Create second y-axis\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Request Counts', color=color) \n",
    "\n",
    "# Plot successful and failed requests\n",
    "ax2.plot(user_counts, successful_requests_per_stage, label='Successfull Requests', color='red', marker='s', linestyle='--')\n",
    "\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Ensure the y-axis starts at 0\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Set x-axis ticks and labels only to show user counts\n",
    "ax1.set_xticks(user_counts)\n",
    "ax1.set_xticklabels(user_counts)\n",
    "\n",
    "plt.title('Energy Efficiency and Request Counts by User Count Stage (Kepler vs PDU)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ],
   "id": "e241f51bf412f44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1a4562148e04cbf3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
